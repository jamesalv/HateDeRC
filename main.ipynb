{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "24658442",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24658442",
        "outputId": "5f8b1847-b0ee-4924-df7c-d2b69efad303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HateDeRC'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 45 (delta 19), reused 29 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (45/45), 4.59 MiB | 10.21 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/HateDeRC\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Delete HateDeRC directory if it exists\n",
        "if os.path.exists('HateDeRC'):\n",
        "  shutil.rmtree('HateDeRC')\n",
        "!git clone https://github.com/jamesalv/HateDeRC\n",
        "%cd HateDeRC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8bccce96",
      "metadata": {
        "id": "8bccce96"
      },
      "outputs": [],
      "source": [
        "from TrainingConfig import TrainingConfig\n",
        "from typing import Dict, Any, Tuple, List\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1f654143",
      "metadata": {
        "id": "1f654143"
      },
      "outputs": [],
      "source": [
        "data_path = 'Data/dataset.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b3618d6e",
      "metadata": {
        "id": "b3618d6e"
      },
      "outputs": [],
      "source": [
        "config = TrainingConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "487ff027",
      "metadata": {
        "id": "487ff027"
      },
      "outputs": [],
      "source": [
        "# Seed all randomness for reproducibility\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(config.seed)\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.manual_seed_all(config.seed)\n",
        "np.random.seed(config.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d93027",
      "metadata": {
        "id": "53d93027"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f81645fa",
      "metadata": {
        "id": "f81645fa"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def deobfuscate_text(text):\n",
        "    \"\"\"\n",
        "    Normalize common text obfuscation patterns to reveal original words.\n",
        "    Useful for hate speech detection and content analysis.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text with potential obfuscations\n",
        "\n",
        "    Returns:\n",
        "        str: Text with obfuscations normalized\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # Make a copy to work with\n",
        "    result = text.lower()\n",
        "\n",
        "    # 1. Handle asterisk/symbol replacements\n",
        "    symbol_patterns = {\n",
        "        # Common profanity\n",
        "        r'f\\*+c?k': 'fuck',\n",
        "        r'f\\*+': 'fuck',\n",
        "        r's\\*+t': 'shit',\n",
        "        r'b\\*+ch': 'bitch',\n",
        "        r'a\\*+s': 'ass',\n",
        "        r'd\\*+n': 'damn',\n",
        "        r'h\\*+l': 'hell',\n",
        "        r'c\\*+p': 'crap',\n",
        "\n",
        "        # Slurs and hate speech terms (be comprehensive for detection)\n",
        "        r'n\\*+g+[aer]+': 'nigger',  # Various n-word obfuscations\n",
        "        r'f\\*+g+[ot]*': 'faggot',\n",
        "        r'r\\*+[dt]ard': 'retard',\n",
        "        r'sp\\*+c': 'spic',\n",
        "\n",
        "        # Other symbols\n",
        "        r'@ss': 'ass',\n",
        "        r'b@tch': 'bitch',\n",
        "        r'sh!t': 'shit',\n",
        "        r'f#ck': 'fuck',\n",
        "        r'd@mn': 'damn',\n",
        "    }\n",
        "\n",
        "    for pattern, replacement in symbol_patterns.items():\n",
        "        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)\n",
        "\n",
        "    # 2. Handle character spacing (f u c k -> fuck)\n",
        "    spacing_patterns = {\n",
        "        r'\\bf\\s+u\\s+c\\s+k\\b': 'fuck',\n",
        "        r'\\bs\\s+h\\s+i\\s+t\\b': 'shit',\n",
        "        r'\\bd\\s+a\\s+m\\s+n\\b': 'damn',\n",
        "        r'\\bh\\s+e\\s+l\\s+l\\b': 'hell',\n",
        "        r'\\ba\\s+s\\s+s\\b': 'ass',\n",
        "        r'\\bc\\s+r\\s+a\\s+p\\b': 'crap',\n",
        "    }\n",
        "\n",
        "    for pattern, replacement in spacing_patterns.items():\n",
        "        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)\n",
        "\n",
        "    # 3. Handle number/letter substitutions\n",
        "    leet_patterns = {\n",
        "        # Basic leet speak\n",
        "        r'\\b3\\s*1\\s*1\\s*3\\b': 'elle',  # 3113 -> elle\n",
        "        r'\\bf4g\\b': 'fag',\n",
        "        r'\\bf4gg0t\\b': 'faggot',\n",
        "        r'\\bn00b\\b': 'noob',\n",
        "        r'\\bl33t\\b': 'leet',\n",
        "        r'\\bh4t3\\b': 'hate',\n",
        "        r'\\b5h1t\\b': 'shit',\n",
        "        r'\\bf0ck\\b': 'fock',\n",
        "    }\n",
        "\n",
        "    for pattern, replacement in leet_patterns.items():\n",
        "        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)\n",
        "\n",
        "    # 4. Handle repeated characters and separators\n",
        "    # Remove excessive punctuation between letters\n",
        "    result = re.sub(r'([a-z])[^\\w\\s]+([a-z])', r'\\1\\2', result)\n",
        "\n",
        "    # Handle underscore separation\n",
        "    result = re.sub(r'([a-z])_+([a-z])', r'\\1\\2', result)\n",
        "\n",
        "    # Handle dot separation\n",
        "    result = re.sub(r'([a-z])\\.+([a-z])', r'\\1\\2', result)\n",
        "\n",
        "    # 5. Handle common misspellings/variations used for evasion\n",
        "    evasion_patterns = {\n",
        "        r'\\bfuk\\b': 'fuck',\n",
        "        r'\\bfuq\\b': 'fuck',\n",
        "        r'\\bfck\\b': 'fuck',\n",
        "        r'\\bshyt\\b': 'shit',\n",
        "        r'\\bshit\\b': 'shit',\n",
        "        r'\\bbiatch\\b': 'bitch',\n",
        "        r'\\bbeatch\\b': 'bitch',\n",
        "        r'\\basshole\\b': 'asshole',\n",
        "        r'\\ba55hole\\b': 'asshole',\n",
        "        r'\\btard\\b': 'retard',\n",
        "        r'\\bfagg\\b': 'fag',\n",
        "    }\n",
        "\n",
        "    for pattern, replacement in evasion_patterns.items():\n",
        "        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)\n",
        "\n",
        "    # 6. Clean up multiple spaces\n",
        "    result = re.sub(r'\\s+', ' ', result).strip()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f070b12b",
      "metadata": {
        "id": "f070b12b"
      },
      "outputs": [],
      "source": [
        "def aggregate_rationales(rationales, labels, post_length, drop_abnormal=False):\n",
        "    \"\"\"\n",
        "    If all 3 annotators are normal → 3 zero spans → average (all zeros).\n",
        "    If k annotators are non-normal and k spans exist → average the k spans (no added zeros).\n",
        "    If k non-normal but fewer than k spans:\n",
        "        If the missing annotators are non-normal → do not fill with zeros; average only existing spans and record rationale_support = #spans.\n",
        "        If the missing annotators are normal (e.g., 2 hate + 1 normal + 2 spans) → append one zero span for the normal.\n",
        "    \"\"\"\n",
        "    count_normal = labels.count(0)\n",
        "    count_hate = labels.count(1)\n",
        "    count_rationales = len(rationales)\n",
        "    pad = np.zeros(post_length, dtype=\"int\").tolist()\n",
        "\n",
        "    # If there are hate labels but no rationales, something is wrong\n",
        "    if count_hate > 0 and count_rationales == 0:\n",
        "        if drop_abnormal:\n",
        "            return None\n",
        "\n",
        "        # Else just fill with 0\n",
        "        return np.zeros(post_length).tolist()\n",
        "\n",
        "    # If all annotators are normal, return all zeros\n",
        "    if count_normal == 3:\n",
        "        return np.zeros(post_length).tolist()\n",
        "\n",
        "    # If we have hate annotators\n",
        "    if count_hate > 0:\n",
        "        # Case 1: Number of rationales matches number of hate annotators\n",
        "        if count_rationales == count_hate:\n",
        "            return np.average(rationales, axis=0).tolist()\n",
        "\n",
        "        # Case 2: Fewer rationales than hate annotators\n",
        "        elif count_rationales < count_hate:\n",
        "            # Add zero padding for normal annotators only\n",
        "            rationales_copy = rationales.copy()\n",
        "            zeros_to_add = count_normal\n",
        "            for _ in range(zeros_to_add):\n",
        "                rationales_copy.append(pad)\n",
        "            return np.average(rationales_copy, axis=0).tolist()\n",
        "\n",
        "        # Case 3: More rationales than hate annotators (shouldn't happen normally)\n",
        "        else:\n",
        "            # Just average what we have\n",
        "            return np.average(rationales, axis=0).tolist()\n",
        "\n",
        "    # Fallback: return zeros if no clear case matches\n",
        "    return np.zeros(post_length).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8d446ddb",
      "metadata": {
        "id": "8d446ddb"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def preprocess_text(raw_text):\n",
        "    preprocessed_text = raw_text\n",
        "    # # Remove HTML tags <>\n",
        "    preprocessed_text = preprocessed_text.replace(\"<\", \"\").replace(\">\", \"\")\n",
        "    # # De-Obsfucate Patterns\n",
        "    preprocessed_text = deobfuscate_text(preprocessed_text)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "\n",
        "def create_text_segment(\n",
        "    text_tokens: List[str], rationale_mask: List[int]\n",
        ") -> List[Tuple[List[str], int]]:\n",
        "    \"\"\"\n",
        "    Process a rationale mask to identify contiguous segments of highlighted text.\n",
        "    Then create a segmented representation of the tokens\n",
        "\n",
        "    Args:\n",
        "        text_tokens: Original text tokens\n",
        "        mask: Binary mask where 1 indicates a highlighted token (this consists of mask from 3 annotators)\n",
        "\n",
        "    Returns:\n",
        "        A list of tuples (text segment, mask value)\n",
        "    \"\"\"\n",
        "    # Handle case where mask is empty (no rationale provided), usually this is normal classification\n",
        "    mask = rationale_mask\n",
        "\n",
        "    # for mask in all_rationale_mask:\n",
        "    # Find breakpoints (transitions between highlighted/1 and non-highlighted/0)\n",
        "    breakpoints = []\n",
        "    mask_values = []\n",
        "\n",
        "    # Always start with position 0\n",
        "    breakpoints.append(0)\n",
        "    mask_values.append(mask[0])\n",
        "\n",
        "    # Find transitions in the mask\n",
        "    for i in range(1, len(mask)):\n",
        "        if mask[i] != mask[i - 1]:\n",
        "            breakpoints.append(i)\n",
        "            mask_values.append(mask[i])\n",
        "\n",
        "    # Always end with the length of the text\n",
        "    if breakpoints[-1] != len(mask):\n",
        "        breakpoints.append(len(mask))\n",
        "\n",
        "    # Create segments based on breakpoints\n",
        "    segments = []\n",
        "    for i in range(len(breakpoints) - 1):\n",
        "        start = breakpoints[i]\n",
        "        end = breakpoints[i + 1]\n",
        "        segments.append((text_tokens[start:end], mask_values[i]))\n",
        "\n",
        "    return segments\n",
        "\n",
        "\n",
        "def align_rationales(tokens, rationales, tokenizer, max_length=128):\n",
        "    \"\"\"\n",
        "    Align rationales with tokenized text while handling different tokenizer formats.\n",
        "\n",
        "    Args:\n",
        "        tokens: Original text tokens\n",
        "        rationales: Original rationale masks\n",
        "        tokenizer: The tokenizer to use\n",
        "        max_length: Maximum sequence length\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with tokenized inputs and aligned rationale masks\n",
        "    \"\"\"\n",
        "    segments = create_text_segment(tokens, rationales)\n",
        "    all_human_rationales = []\n",
        "    all_input_ids = []\n",
        "    all_attention_mask = []\n",
        "    all_token_type_ids = []\n",
        "    all_rationales = []\n",
        "    for text_segment, rationale_value in segments:\n",
        "        inputs = {}\n",
        "        concatenated_text = \" \".join(text_segment)\n",
        "        processed_segment = preprocess_text(concatenated_text)\n",
        "        tokenized = tokenizer(\n",
        "            processed_segment, add_special_tokens=False, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Extract the relevant data\n",
        "        segment_input_ids = tokenized[\"input_ids\"][0]\n",
        "        segment_attention_mask = tokenized[\"attention_mask\"][0]\n",
        "        # Handle token_type_ids if present\n",
        "        if \"token_type_ids\" in tokenized:\n",
        "            segment_token_type_ids = tokenized[\"token_type_ids\"][0]\n",
        "            all_token_type_ids.extend(segment_token_type_ids)\n",
        "\n",
        "        # Add input IDs and attention mask\n",
        "        all_input_ids.extend(segment_input_ids)\n",
        "        all_attention_mask.extend(segment_attention_mask)\n",
        "\n",
        "        # Add rationales (excluding special tokens)\n",
        "        segment_rationales = [rationale_value] * len(segment_input_ids)\n",
        "        all_rationales.extend(segment_rationales)\n",
        "    # Get special token IDs\n",
        "    cls_token_id = tokenizer.cls_token_id\n",
        "    sep_token_id = tokenizer.sep_token_id\n",
        "\n",
        "    # Add special tokens at the beginning and end\n",
        "    all_input_ids = [cls_token_id] + all_input_ids + [sep_token_id]\n",
        "    all_attention_mask = [1] + all_attention_mask + [1]\n",
        "\n",
        "    # Handle token_type_ids if the model requires it\n",
        "    if hasattr(tokenizer, \"create_token_type_ids_from_sequences\"):\n",
        "        all_token_type_ids = tokenizer.create_token_type_ids_from_sequences(\n",
        "            all_input_ids[1:-1]\n",
        "        )\n",
        "    elif all_token_type_ids:\n",
        "        all_token_type_ids = [0] + all_token_type_ids + [0]\n",
        "    else:\n",
        "        all_token_type_ids = [0] * len(all_input_ids)\n",
        "\n",
        "    # Check tokenized vs rationales length\n",
        "    if len(all_input_ids) != len(all_attention_mask):\n",
        "        print(\"Warning: length of tokens and rationales do not match\")\n",
        "\n",
        "    # Add zero rationale values for special tokens\n",
        "    all_rationales = [0] + all_rationales + [0]\n",
        "\n",
        "    # Truncate to max length if needed\n",
        "    if len(all_input_ids) > max_length:\n",
        "        print(\"WARNING: NEED TO TRUNCATE\")\n",
        "        all_input_ids = all_input_ids[:max_length]\n",
        "        all_attention_mask = all_attention_mask[:max_length]\n",
        "        all_token_type_ids = all_token_type_ids[:max_length]\n",
        "        all_rationales = all_rationales[:max_length]\n",
        "\n",
        "    # Pad to max_length if needed\n",
        "    pad_token_id = tokenizer.pad_token_id\n",
        "    padding_length = max_length - len(all_input_ids)\n",
        "\n",
        "    if padding_length > 0:\n",
        "        all_input_ids = all_input_ids + [pad_token_id] * padding_length\n",
        "        all_attention_mask = all_attention_mask + [0] * padding_length\n",
        "        all_token_type_ids = all_token_type_ids + [0] * padding_length\n",
        "        all_rationales = all_rationales + [0] * padding_length\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    inputs = {\n",
        "        \"input_ids\": torch.tensor([all_input_ids], dtype=torch.long),\n",
        "        \"attention_mask\": torch.tensor([all_attention_mask], dtype=torch.long),\n",
        "        \"token_type_ids\": (\n",
        "            torch.tensor([all_token_type_ids], dtype=torch.long)\n",
        "            if \"token_type_ids\" in tokenizer.model_input_names\n",
        "            else None\n",
        "        ),\n",
        "        \"rationales\": torch.tensor([all_rationales], dtype=torch.float32),\n",
        "    }\n",
        "\n",
        "    # Remove None values\n",
        "    inputs = {k: v for k, v in inputs.items() if v is not None}\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import string\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import more_itertools as mit\n",
        "\n",
        "def find_ranges(iterable):\n",
        "    \"\"\"Yield range of consecutive numbers.\"\"\"\n",
        "    for group in mit.consecutive_groups(iterable):\n",
        "        group = list(group)\n",
        "        if len(group) == 1:\n",
        "            yield group[0]\n",
        "        else:\n",
        "            yield group[0], group[-1]\n",
        "\n",
        "def process_and_convert_data(data, tokenizer, post_id_divisions, save_path='Data/explanations/', drop_abnormal=False):\n",
        "    \"\"\"\n",
        "    Combined function that processes raw entries and converts to ERASER format in one pass.\n",
        "    Also splits data into train/val/test sets.\n",
        "    \"\"\"\n",
        "    print(\"Processing and converting data...\")\n",
        "\n",
        "    # Initialize outputs\n",
        "    train_data = []\n",
        "    val_data = []\n",
        "    test_data = []\n",
        "    dropped = 0\n",
        "\n",
        "    # Create directories if saving splits\n",
        "    if save_path:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        os.makedirs(os.path.join(save_path, 'docs'), exist_ok=True)\n",
        "        train_fp = open(os.path.join(save_path, 'train.jsonl'), 'w')\n",
        "        val_fp = open(os.path.join(save_path, 'val.jsonl'), 'w')\n",
        "        test_fp = open(os.path.join(save_path, 'test.jsonl'), 'w')\n",
        "\n",
        "    for key, value in tqdm(data.items()):\n",
        "        try:\n",
        "            # Extract labels\n",
        "            labels = [1 if annot[\"label\"] in ['hatespeech', 'offensive'] else 0\n",
        "                     for annot in value[\"annotators\"]]\n",
        "\n",
        "            # Process rationales\n",
        "            rationales = value.get(\"rationales\", [])\n",
        "            aggregated_rationale = aggregate_rationales(\n",
        "                rationales, labels, len(value[\"post_tokens\"]), drop_abnormal=drop_abnormal\n",
        "            )\n",
        "\n",
        "            if aggregated_rationale is None:\n",
        "                dropped += 1\n",
        "                continue\n",
        "\n",
        "            inputs = align_rationales(value['post_tokens'], aggregated_rationale, tokenizer)\n",
        "\n",
        "            # Calculate labels\n",
        "            hard_label = Counter(labels).most_common(1)[0][0]\n",
        "            soft_label = sum(labels) / len(labels)\n",
        "\n",
        "            # Determine target groups (mentioned at least 3 times)\n",
        "            target_groups = [t for annot in value['annotators'] for t in annot['target']]\n",
        "            filtered_targets = [k for k, v in Counter(target_groups).items() if v > 2]\n",
        "\n",
        "            # Create processed entry\n",
        "            processed_entry = {\n",
        "                'post_id': key,\n",
        "                'input_ids': inputs['input_ids'],\n",
        "                'attention_mask': inputs['attention_mask'],\n",
        "                'rationales': inputs['rationales'],\n",
        "                'raw_text': \" \".join(value['post_tokens']),\n",
        "                'hard_label': hard_label,\n",
        "                'soft_label': soft_label,\n",
        "                'target_groups': filtered_targets\n",
        "            }\n",
        "\n",
        "            # Convert to ERASER format if it's hateful/offensive content\n",
        "            if hard_label == 1 and save_path:\n",
        "                input_ids_list = inputs['input_ids'].squeeze().tolist()\n",
        "                rationales_list = inputs['rationales'].squeeze().ceil().int().tolist()\n",
        "\n",
        "                # Build evidences\n",
        "                evidences = []\n",
        "                indexes = sorted([i for i, each in enumerate(rationales_list) if each == 1])\n",
        "                for span in find_ranges(indexes):\n",
        "                    if isinstance(span, int):\n",
        "                        start, end = span, span + 1\n",
        "                    else:\n",
        "                        start, end = span[0], span[1] + 1\n",
        "\n",
        "                    evidences.append({\n",
        "                        \"docid\": key,\n",
        "                        \"end_sentence\": -1,\n",
        "                        \"end_token\": end,\n",
        "                        \"start_sentence\": -1,\n",
        "                        \"start_token\": start,\n",
        "                        \"text\": ' '.join([str(x) for x in input_ids_list[start:end]])\n",
        "                    })\n",
        "\n",
        "                eraser_entry = {\n",
        "                    'annotation_id': key,\n",
        "                    'classification': hard_label,\n",
        "                    'evidences': [evidences],\n",
        "                    'query': \"What is the class?\",\n",
        "                    'query_type': None\n",
        "                }\n",
        "\n",
        "                # Save document\n",
        "                with open(os.path.join(save_path, 'docs', key), 'w') as fp:\n",
        "                    fp.write(' '.join([str(x) for x in input_ids_list]))\n",
        "\n",
        "                # Write to appropriate split\n",
        "                if key in post_id_divisions['train']:\n",
        "                    train_fp.write(json.dumps(eraser_entry) + '\\n')\n",
        "                elif key in post_id_divisions['val']:\n",
        "                    val_fp.write(json.dumps(eraser_entry) + '\\n')\n",
        "                elif key in post_id_divisions['test']:\n",
        "                    test_fp.write(json.dumps(eraser_entry) + '\\n')\n",
        "\n",
        "            # Add to appropriate split list\n",
        "            if key in post_id_divisions['train']:\n",
        "                train_data.append(processed_entry)\n",
        "            elif key in post_id_divisions['val']:\n",
        "                val_data.append(processed_entry)\n",
        "            elif key in post_id_divisions['test']:\n",
        "                test_data.append(processed_entry)\n",
        "\n",
        "        except Exception as e:\n",
        "            dropped += 1\n",
        "            print(f\"Error processing {key}: {e}\")\n",
        "\n",
        "    if save_path:\n",
        "        train_fp.close()\n",
        "        val_fp.close()\n",
        "        test_fp.close()\n",
        "\n",
        "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}, Dropped: {dropped}\")\n",
        "\n",
        "    return {\n",
        "        'train': train_data,\n",
        "        'val': val_data,\n",
        "        'test': test_data\n",
        "    }"
      ],
      "metadata": {
        "id": "pEC9l6Mr6xo0"
      },
      "id": "pEC9l6Mr6xo0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "with open('Data/post_id_divisions.json') as file:\n",
        "    post_id_divisions = json.load(file)\n",
        "\n",
        "# Process everything in one pass\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "splits = process_and_convert_data(\n",
        "    data=data,\n",
        "    tokenizer=tokenizer,\n",
        "    post_id_divisions=post_id_divisions,\n",
        "    save_path='Data/explanations/',\n",
        "    drop_abnormal=False\n",
        ")\n",
        "\n",
        "# Access splits directly\n",
        "train_data = splits['train']\n",
        "val_data = splits['val']\n",
        "test_data = splits['test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "9ebb232a0b9649789495ec0c8a519e1a",
            "d755aa71d5a1461cb932778dc5deaf52",
            "30b2fc6ceebb4da083da94a206cdc32e",
            "f872f5f79a884eaca0f07e00bc1a2eca",
            "1ac419c560cb44149a6b54d2c256e1aa",
            "e40ac1cd6e2344ca8d8ede79e35791cb",
            "000d556ee6514ee4a84badad7cce732d",
            "222943fb54e5426d89b2d50051135306",
            "6168a397e2994c0289bf267be8bff0e7",
            "ed5921c0c4994155a08f060c98de0228",
            "0466e0260a5f4774af5c4b76b495d15f",
            "838074dd3de54ba28ff6888918598f54",
            "4108f81df6394bb1956157ffa08d5b19",
            "6dcba1504ae6444a9f8b1eb310b1c0ba",
            "2149e2e0f02d44be95617cf8c57dc8e8",
            "955bc92f2d6141949e91648f36940ed9",
            "01f0ad4c4f884d5ab4bae38a6d5b8f12",
            "658618d078554305b8d86b1a882f9ae9",
            "e8ac744ceb77418baeea1a40b2213bcf",
            "036b2b14b78a46beb319571bc408bf94",
            "42983923305347428db2a3acb7d8fa98",
            "95a276c276594117b51a9ed4361ad4d3",
            "d514fc32c3b14890866e4e340eb65ff7",
            "27983a49e3af4cc799d4b47291fa1d2e",
            "a8e708b18cdb40078565f90ca9aec543",
            "2ec85da142384b2499d0d5cec5516cb6",
            "c6a377b8f1994f7ea5853c5ea47c072c",
            "7cbf881bf084483594c4982f61ddee22",
            "555f094a99a448ed92206c2b2e40a48e",
            "e09f9d26e7554480be056472a37727b9",
            "85183a453759410090f84533fd6a94d4",
            "658de63d6be44d67abae51be45398ed2",
            "5a27b15a14d0485d9bec469f9fbc8297",
            "b0bf17679f9b4e74be363704aa7bf120",
            "624199c0f53447e7b4e32d371e4016eb",
            "84892e9a9e0f4dc8b74b975392618dc6",
            "662feb5d7e6946a18fba9a23145fc034",
            "1be37b84a1ae427fa1a636cdd98a6fd7",
            "199507e489064a3fb942faf130588a3d",
            "9cae2ba8f08e46108daebf7cf8de1618",
            "d4a64806bec5463c80471893e695e179",
            "df22cfc7b3de4d5595f10e4250223801",
            "0e1b35c05596461d8b8005b6a62506da",
            "e31b9ffcc76a4885a4b32e84a2fab004"
          ]
        },
        "id": "43NMFuwv62Q4",
        "outputId": "4dee724c-5765-4690-8a36-b839de5a29b9"
      },
      "id": "43NMFuwv62Q4",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ebb232a0b9649789495ec0c8a519e1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "838074dd3de54ba28ff6888918598f54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d514fc32c3b14890866e4e340eb65ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0bf17679f9b4e74be363704aa7bf120"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing and converting data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 7331/20148 [00:25<00:25, 499.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: NEED TO TRUNCATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 17979/20148 [00:42<00:03, 620.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 24439295_gab: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20148/20148 [00:46<00:00, 437.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 15382, Val: 1922, Test: 1924, Dropped: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "87c63ecf",
      "metadata": {
        "id": "87c63ecf"
      },
      "outputs": [],
      "source": [
        "from HateDataset import HateDataset\n",
        "\n",
        "# Create datasets with pre-tokenized data\n",
        "train_dataset = HateDataset(data=train_data)\n",
        "val_dataset = HateDataset(data=val_data)\n",
        "test_dataset = HateDataset(data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f4887f43",
      "metadata": {
        "id": "f4887f43"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False) # Use shuffle=False for validation\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) # Use shuffle=False for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2f509bc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a035f097a51b4e59b5f240e08a959dda",
            "3049e83d2f184ca2b7657db368f49a1d",
            "ee1a88ab031c4327ad18b3a48929bab0",
            "6ea187bc06d84f018673dfc981571a6e",
            "7c2b46d111114553b94fcd2351e9f7bd",
            "7f9d7443369a4cbf97048d9952396b58",
            "2642b7f8abf24bfabef78ef219768375",
            "e8ab7c8eca5442a88af511856f58b271",
            "effb7cca8a914550a68775728bdeb881",
            "606c6a11e2564fc68ec19f701e48c625",
            "c46fe7448c5a46428cd007265094139f"
          ]
        },
        "id": "2f509bc0",
        "outputId": "9e15bf1c-951e-4907-e4fd-4642209262cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a035f097a51b4e59b5f240e08a959dda"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from HateClassifier import HateClassifier\n",
        "model = HateClassifier(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "aab913f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aab913f8",
        "outputId": "2a659537-3fb8-436c-ef14-d43246861cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device: cuda\n",
            "Model: distilbert-base-uncased\n",
            "Epochs: 2\n",
            "Batch size: 32\n",
            "Gradient accumulation steps: 1\n",
            "Effective batch size: 32\n",
            "Learning rate: 1e-05\n",
            "Mixed precision (AMP): True\n",
            "Gradient clipping: 1.0\n",
            "============================================================\n",
            "\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 481/481 [00:53<00:00,  8.92batch/s, loss=0.514]\n",
            "Evaluating: 100%|██████████| 61/61 [00:01<00:00, 31.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Summary:\n",
            "  Train Loss: 0.5140\n",
            "  Val Loss:   0.4677\n",
            "  Val Acc:    0.7711\n",
            "  Val F1:     0.7647\n",
            "  ✓ New best model saved! (F1: 0.7647)\n",
            "\n",
            "Epoch 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 481/481 [00:57<00:00,  8.43batch/s, loss=0.418]\n",
            "Evaluating: 100%|██████████| 61/61 [00:01<00:00, 32.81batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary:\n",
            "  Train Loss: 0.4179\n",
            "  Val Loss:   0.4680\n",
            "  Val Acc:    0.7695\n",
            "  Val F1:     0.7633\n",
            "\n",
            "============================================================\n",
            "Training completed!\n",
            "Best F1 Score: 0.7647\n",
            "Training history saved to: ./checkpoints/training_history.json\n"
          ]
        }
      ],
      "source": [
        "history = model.train(train_dataloader=train_loader, val_dataloader=val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4103f12a",
      "metadata": {
        "id": "4103f12a"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c2d21fc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2d21fc2",
        "outputId": "dff170fc-bccf-4e00-e107-4b436ab1d221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference on 61 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:01<00:00, 31.52batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     0.4493\n",
            "  Test Accuracy: 0.7968\n",
            "  Test F1:       0.7902\n",
            "============================================================\n",
            "Results saved to prediction_results.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "result = model.predict(test_dataloader=test_loader, return_attentions=True)\n",
        "\n",
        "# Save the result to a file\n",
        "with open('prediction_results.pkl', 'wb') as f:\n",
        "  pickle.dump(result, f)\n",
        "\n",
        "print(\"Results saved to prediction_results.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0caf972c",
      "metadata": {
        "id": "0caf972c"
      },
      "source": [
        "## Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "40280671",
      "metadata": {
        "id": "40280671"
      },
      "outputs": [],
      "source": [
        "def get_bias_evaluation_samples(data, method, group):\n",
        "    \"\"\"\n",
        "    Get positive and negative sample IDs for bias evaluation based on method and group\n",
        "\n",
        "    Args:\n",
        "        data: list of data entries\n",
        "        method: Bias evaluation method ('subgroup', 'bpsn', or 'bnsp')\n",
        "        group: Target group to evaluate\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (positive_ids, negative_ids)\n",
        "    \"\"\"\n",
        "    positive_ids = []\n",
        "    negative_ids = []\n",
        "\n",
        "    for idx, row in enumerate(data):\n",
        "        target_groups = row['target_groups']\n",
        "        if target_groups is None:\n",
        "            continue\n",
        "\n",
        "        is_in_group = group in target_groups\n",
        "\n",
        "        # Convert various label formats to binary toxic/non-toxic\n",
        "        if 'hard_label' in row:\n",
        "            is_toxic = row['hard_label'] == 1\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if method == 'subgroup':\n",
        "            # Only consider samples mentioning the group\n",
        "            if is_in_group:\n",
        "                if is_toxic:\n",
        "                    positive_ids.append(idx)\n",
        "                else:\n",
        "                    negative_ids.append(idx)\n",
        "\n",
        "        elif method == 'bpsn':\n",
        "            # Compare non-toxic posts mentioning the group with toxic posts NOT mentioning the group\n",
        "            if is_in_group and not is_toxic:\n",
        "                negative_ids.append(idx)\n",
        "            elif not is_in_group and is_toxic:\n",
        "                positive_ids.append(idx)\n",
        "\n",
        "        elif method == 'bnsp':\n",
        "            # Compare toxic posts mentioning the group with non-toxic posts NOT mentioning the group\n",
        "            if is_in_group and is_toxic:\n",
        "                positive_ids.append(idx)\n",
        "            elif not is_in_group and not is_toxic:\n",
        "                negative_ids.append(idx)\n",
        "\n",
        "    return positive_ids, negative_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "79edfa7d",
      "metadata": {
        "id": "79edfa7d"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def calculate_gmb_metrics(\n",
        "    test_data: List[Dict[str, Any]],\n",
        "    probabilities: np.ndarray,\n",
        "    target_groups: List[str]\n",
        "):\n",
        "    \"\"\"\n",
        "    Calculate GMB (Generalized Mean of Bias) AUC metrics from model predictions\n",
        "\n",
        "    Args:\n",
        "        probabilities: Model's probability outputs\n",
        "        test_data: List of test data entries\n",
        "        target_groups: List of target groups to evaluate\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with GMB metrics\n",
        "    \"\"\"\n",
        "    # Create mappings from post_id to predictions and ground truth\n",
        "    prediction_scores = defaultdict(lambda: defaultdict(dict))\n",
        "    ground_truth = {}\n",
        "\n",
        "    for idx, row in enumerate(test_data):\n",
        "        prediction_scores[idx] = probabilities[idx, 1]\n",
        "        ground_truth[idx] = row['hard_label']\n",
        "\n",
        "    # Calculate metrics for each target group and method\n",
        "    bias_metrics = {}\n",
        "    methods = ['subgroup', 'bpsn', 'bnsp']\n",
        "\n",
        "    for method in methods:\n",
        "        bias_metrics[method] = {}  # Initialize nested dictionary for each method\n",
        "        for group in target_groups:\n",
        "            # Get positive and negative samples based on the method\n",
        "            positive_ids, negative_ids = get_bias_evaluation_samples(test_data, method, group)\n",
        "\n",
        "            if len(positive_ids) == 0 or len(negative_ids) == 0:\n",
        "                print(f\"Skipping {method} for group {group}: no samples found\")\n",
        "                continue  # Skip if no samples for this group/method\n",
        "\n",
        "            # Collect ground truth and predictions\n",
        "            y_true = []\n",
        "            y_score = []\n",
        "\n",
        "            for post_id in positive_ids:\n",
        "                if post_id in ground_truth and post_id in prediction_scores:\n",
        "                    y_true.append(ground_truth[post_id])\n",
        "                    y_score.append(prediction_scores[post_id])\n",
        "\n",
        "            for post_id in negative_ids:\n",
        "                if post_id in ground_truth and post_id in prediction_scores:\n",
        "                    y_true.append(ground_truth[post_id])\n",
        "                    y_score.append(prediction_scores[post_id])\n",
        "\n",
        "            # Calculate AUC if we have enough samples with both classes\n",
        "            if len(y_true) > 10 and len(set(y_true)) > 1:\n",
        "                try:\n",
        "                    auc = roc_auc_score(y_true, y_score)\n",
        "                    bias_metrics[method][group] = auc\n",
        "                except ValueError:\n",
        "                    print(f\"Could not compute AUC for {method} and group {group} due to ValueError\")\n",
        "                    pass\n",
        "\n",
        "    # Calculate GMB for each method\n",
        "    gmb_metrics = {}\n",
        "    power = -5  # Power parameter for generalized mean\n",
        "\n",
        "    for method in methods:\n",
        "        if not bias_metrics[method]:\n",
        "            continue\n",
        "\n",
        "        scores = list(bias_metrics[method].values())\n",
        "        if not scores:\n",
        "            continue\n",
        "\n",
        "        # Calculate generalized mean with p=-5\n",
        "        power_mean = np.mean([score ** power for score in scores]) ** (1/power)\n",
        "        gmb_metrics[f'GMB-{method.upper()}-AUC'] = power_mean\n",
        "\n",
        "    # Calculate a combined GMB score that includes all methods\n",
        "    all_scores = []\n",
        "    for method in methods:\n",
        "        all_scores.extend(list(bias_metrics[method].values()))\n",
        "\n",
        "    if all_scores:\n",
        "        gmb_metrics['GMB-COMBINED-AUC'] = np.mean([score ** power for score in all_scores]) ** (1/power)\n",
        "\n",
        "    return gmb_metrics, bias_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "all_target_groups = list(chain.from_iterable(d['target_groups'] for d in train_data + val_data + test_data))"
      ],
      "metadata": {
        "id": "ys17p1JQ_IUD"
      },
      "id": "ys17p1JQ_IUD",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d156cab7",
      "metadata": {
        "id": "d156cab7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "# Get top 10 most common target groups in the full dataset\n",
        "\n",
        "# Remove None\n",
        "all_target_groups = [group for group in all_target_groups if group != 'None' and group != 'Other']\n",
        "counter = Counter(all_target_groups)\n",
        "\n",
        "n_common = 10\n",
        "bias_target_groups = [tg[0] for tg in counter.most_common(n_common)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ffc9f3e0",
      "metadata": {
        "id": "ffc9f3e0"
      },
      "outputs": [],
      "source": [
        "gmb_metrics, bias_details = calculate_gmb_metrics(\n",
        "  test_data=test_data,\n",
        "  probabilities=result['probabilities'],\n",
        "  target_groups=bias_target_groups\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9c02645d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c02645d",
        "outputId": "27ecdfff-4a9a-4c79-eb76-9621b5b444f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GMB-Metrics\n",
            "GMB-SUBGROUP-AUC: 0.8081792990282538\n",
            "GMB-BPSN-AUC: 0.7716453586649427\n",
            "GMB-BNSP-AUC: 0.8105021011920741\n",
            "GMB-COMBINED-AUC: 0.7955413062110042\n"
          ]
        }
      ],
      "source": [
        "print('GMB-Metrics')\n",
        "for key, value in gmb_metrics.items():\n",
        "  print(f'{key}: {value}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "814a2279",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "814a2279",
        "outputId": "b9d659e6-97ee-4404-b0e8-c4b188f035df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bias Details\n",
            "\n",
            "Metrics: subgroup\n",
            "African: 0.8964992389649924\n",
            "Jewish: 0.8120300751879699\n",
            "Islam: 0.9719626168224299\n",
            "Homosexual: 0.8660714285714286\n",
            "Women: 0.6092896174863388\n",
            "Refugee: 0.7757575757575758\n",
            "Arab: 0.896551724137931\n",
            "Hispanic: 1.0\n",
            "Asian: 1.0\n",
            "Caucasian: 0.8666666666666667\n",
            "\n",
            "Metrics: bpsn\n",
            "African: 0.6941133983387504\n",
            "Jewish: 0.5944003964321111\n",
            "Islam: 0.9379227053140097\n",
            "Homosexual: 0.8585760517799352\n",
            "Women: 0.7906259636139378\n",
            "Refugee: 0.915990381725278\n",
            "Arab: 0.7466307277628033\n",
            "Hispanic: 0.868515205724508\n",
            "Asian: 0.9844858156028369\n",
            "Caucasian: 0.9733806566104704\n",
            "\n",
            "Metrics: bnsp\n",
            "African: 0.9400208674040598\n",
            "Jewish: 0.9465324622610511\n",
            "Islam: 0.8941330514379069\n",
            "Homosexual: 0.8827938749312305\n",
            "Women: 0.7830403920905864\n",
            "Refugee: 0.7310062818537395\n",
            "Arab: 0.941630977085081\n",
            "Hispanic: 0.9777262057191635\n",
            "Asian: 0.8748856777025791\n",
            "Caucasian: 0.634957264957265\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Bias Details')\n",
        "print()\n",
        "for key, entry in bias_details.items():\n",
        "  print(f\"Metrics: {key}\")\n",
        "  for subgroup, value in entry.items():\n",
        "    print(f'{subgroup}: {value}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b1ac3f",
      "metadata": {
        "id": "39b1ac3f"
      },
      "source": [
        "# XAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import List, Dict, Tuple\n",
        "from sklearn.metrics import precision_recall_curve, auc, f1_score, precision_score, recall_score\n",
        "\n",
        "class FaithfulnessMetrics:\n",
        "  \"\"\"\n",
        "  Compute faithfulness metrics using the model's existing predict() method.\n",
        "  Creates modified datasets and uses DataLoader for efficient batched processing.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, model, tokenizer, dataset_class, batch_size=32):\n",
        "      self.model = model\n",
        "      self.tokenizer = tokenizer\n",
        "      self.dataset_class = dataset_class\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      # Get special token IDs\n",
        "      self.special_token_ids = {\n",
        "          tokenizer.cls_token_id,\n",
        "          tokenizer.sep_token_id,\n",
        "      }\n",
        "      self.special_token_ids = {x for x in self.special_token_ids if x is not None}\n",
        "\n",
        "  def compute_all_metrics(\n",
        "      self,\n",
        "      test_data: List[Dict],  # Your original test data\n",
        "      test_results: List[Dict], # Results from prediction\n",
        "      k: int = 5  # Number of top tokens to consider\n",
        "  ) -> Dict[str, float]:\n",
        "      \"\"\"\n",
        "      Compute all ERASER metrics efficiently using DataLoader approach\n",
        "\n",
        "      Args:\n",
        "          test_data: List of test instances (each with input_ids, attention_mask, rationales, labels)\n",
        "          test_results: List of dictionaries containing attention scores for each instance\n",
        "\n",
        "      Returns:\n",
        "          Dictionary with all metrics\n",
        "      \"\"\"\n",
        "      print(\"Computing ERASER metrics using DataLoader approach...\")\n",
        "\n",
        "      # Extract lists for easier processing\n",
        "      input_ids_list = [item['input_ids'] for item in test_data]\n",
        "      attention_masks_list = [item['attention_mask'] for item in test_data]\n",
        "      human_rationales = [item['rationales'] for item in test_data]\n",
        "      attention_scores = [item for item in test_results['attentions']]\n",
        "\n",
        "      # 1. Extract top-k as hard predictions\n",
        "      hard_predictions = self._extract_top_k_tokens(\n",
        "          attention_scores, attention_masks_list, input_ids_list, k\n",
        "      )\n",
        "\n",
        "      # 2. PLAUSIBILITY METRICS\n",
        "      print(\"\\n[1/3] Computing plausibility metrics...\")\n",
        "      auprc = self._compute_auprc(\n",
        "          attention_scores, human_rationales, attention_masks_list, input_ids_list\n",
        "      )\n",
        "      token_f1, token_prec, token_rec = self._compute_token_f1(\n",
        "          hard_predictions, human_rationales, attention_masks_list\n",
        "      )\n",
        "\n",
        "      # 3. FAITHFULNESS METRICS\n",
        "      print(\"[2/3] Computing comprehensiveness scores...\")\n",
        "      comprehensiveness_scores = self._compute_comprehensiveness(\n",
        "          test_data, test_results, hard_predictions\n",
        "      )\n",
        "\n",
        "      print(\"[3/3] Computing sufficiency scores...\")\n",
        "      sufficiency_scores = self._compute_sufficiency(\n",
        "          test_data, test_results, hard_predictions\n",
        "      )\n",
        "\n",
        "      return {\n",
        "          # Plausibility\n",
        "          'auprc': auprc,\n",
        "          'token_f1': token_f1,\n",
        "          'token_precision': token_prec,\n",
        "          'token_recall': token_rec,\n",
        "\n",
        "          # Faithfulness\n",
        "          'comprehensiveness': np.mean(comprehensiveness_scores),\n",
        "          'sufficiency': np.mean(sufficiency_scores),\n",
        "\n",
        "          # Additional\n",
        "          'avg_rationale_length': k,\n",
        "      }\n",
        "\n",
        "  def _calculate_average_rationale_length(\n",
        "      self,\n",
        "      human_rationales: List[torch.Tensor],\n",
        "      attention_masks_list: List[torch.Tensor],\n",
        "      input_ids_list: List[torch.Tensor]\n",
        "  ) -> int:\n",
        "      \"\"\"Calculate average number of content rationale tokens\"\"\"\n",
        "      lengths = []\n",
        "      for idx, (rat, mask) in enumerate(zip(human_rationales, attention_masks_list)):\n",
        "          valid_positions = mask.bool().cpu().numpy().flatten()\n",
        "\n",
        "          # Exclude special tokens\n",
        "          input_ids = input_ids_list[idx].cpu().numpy().flatten()\n",
        "          is_special = np.isin(input_ids, list(self.special_token_ids))\n",
        "          content_positions = valid_positions & ~is_special\n",
        "\n",
        "          rat_count = (rat.cpu().numpy().flatten()[content_positions] == 1).sum()\n",
        "          lengths.append(rat_count)\n",
        "\n",
        "      return max(1, int(np.mean(lengths)))\n",
        "\n",
        "  def _extract_top_k_tokens(\n",
        "      self,\n",
        "      attention_scores: List[np.ndarray],\n",
        "      attention_masks_list: List[torch.Tensor],\n",
        "      input_ids_list: List[torch.Tensor],\n",
        "      k: int\n",
        "  ) -> List[np.ndarray]:\n",
        "      \"\"\"Extract top-k content tokens as hard predictions\"\"\"\n",
        "      hard_predictions = []\n",
        "\n",
        "      for idx, (attn, mask) in enumerate(zip(attention_scores, attention_masks_list)):\n",
        "          pred_mask = np.zeros_like(attn, dtype=int)\n",
        "          valid_positions = mask.bool().cpu().numpy().flatten()\n",
        "\n",
        "          # Exclude special tokens\n",
        "          input_ids = input_ids_list[idx].cpu().numpy().flatten()\n",
        "          is_special = np.isin(input_ids, list(self.special_token_ids))\n",
        "          content_positions = valid_positions & ~is_special\n",
        "\n",
        "          content_attn = attn[content_positions]\n",
        "\n",
        "          if k > 0 and len(content_attn) > 0:\n",
        "              k_actual = min(k, len(content_attn))\n",
        "              top_k_within_content = np.argsort(content_attn)[-k_actual:]\n",
        "              content_indices = np.where(content_positions)[0]\n",
        "              top_k_indices = content_indices[top_k_within_content]\n",
        "              pred_mask[top_k_indices] = 1\n",
        "\n",
        "          hard_predictions.append(pred_mask)\n",
        "\n",
        "      return hard_predictions\n",
        "\n",
        "  def _compute_auprc(\n",
        "      self,\n",
        "      attention_scores: List[np.ndarray],\n",
        "      human_rationales: List[torch.Tensor],\n",
        "      attention_masks_list: List[torch.Tensor],\n",
        "      input_ids_list: List[torch.Tensor]\n",
        "  ) -> float:\n",
        "      \"\"\"Compute AUPRC for soft attention scores\"\"\"\n",
        "      all_scores = []\n",
        "      all_labels = []\n",
        "\n",
        "      for idx, (attn, rat, mask) in enumerate(zip(attention_scores, human_rationales, attention_masks_list)):\n",
        "          valid_positions = mask.bool().cpu().numpy().flatten()\n",
        "\n",
        "          # Exclude special tokens\n",
        "          input_ids = input_ids_list[idx].cpu().numpy().flatten()\n",
        "          is_special = np.isin(input_ids, list(self.special_token_ids))\n",
        "          content_positions = valid_positions & ~is_special\n",
        "\n",
        "          all_scores.extend(attn[content_positions].tolist())\n",
        "          all_labels.extend(rat.cpu().numpy().flatten()[content_positions].astype(int).tolist())\n",
        "\n",
        "      all_scores = np.array(all_scores, dtype=float)\n",
        "      all_labels = np.array(all_labels, dtype=int)\n",
        "\n",
        "      if len(np.unique(all_labels)) < 2:\n",
        "          print(f\"Warning: Only one class in labels: {np.unique(all_labels)}\")\n",
        "          return 0.0\n",
        "\n",
        "      precision, recall, _ = precision_recall_curve(all_labels, all_scores)\n",
        "      return auc(recall, precision)\n",
        "\n",
        "  def _compute_token_f1(\n",
        "      self,\n",
        "      hard_predictions: List[np.ndarray],\n",
        "      human_rationales: List[torch.Tensor],\n",
        "      attention_masks_list: List[torch.Tensor]\n",
        "  ) -> Tuple[float, float, float]:\n",
        "      \"\"\"Compute token-level F1, Precision, Recall\"\"\"\n",
        "      all_preds = []\n",
        "      all_labels = []\n",
        "\n",
        "      for pred, rat, mask in zip(hard_predictions, human_rationales, attention_masks_list):\n",
        "          valid_positions = mask.bool().cpu().numpy().flatten()\n",
        "          all_preds.extend(pred[valid_positions].astype(int).tolist())\n",
        "          all_labels.extend(rat.cpu().numpy().flatten()[valid_positions].astype(int).tolist())\n",
        "\n",
        "      all_preds = np.array(all_preds, dtype=int)\n",
        "      all_labels = np.array(all_labels, dtype=int)\n",
        "\n",
        "      f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "      precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "      recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "      return f1, precision, recall\n",
        "\n",
        "  def _compute_comprehensiveness(\n",
        "      self,\n",
        "      test_data: List[Dict],\n",
        "      test_results: List[Dict],\n",
        "      hard_predictions: List[np.ndarray]\n",
        "  ) -> List[float]:\n",
        "      \"\"\"\n",
        "      Compute comprehensiveness: how much does REMOVING rationales hurt?\n",
        "      Uses DataLoader approach for efficiency\n",
        "      \"\"\"\n",
        "      # Create modified dataset (remove rationales from attention mask)\n",
        "      modified_data = []\n",
        "      for item, rationale_mask in zip(test_data, hard_predictions):\n",
        "          modified_item = self._create_comprehensiveness_instance(item, rationale_mask)\n",
        "          modified_data.append(modified_item)\n",
        "\n",
        "      # Create DataLoader\n",
        "      modified_dataset = self.dataset_class(modified_data)\n",
        "      modified_loader = DataLoader(\n",
        "          modified_dataset,\n",
        "          batch_size=self.batch_size,\n",
        "          shuffle=False\n",
        "      )\n",
        "\n",
        "      # Get predictions using model's predict method\n",
        "      results = self.model.predict(modified_loader, return_attentions=False)\n",
        "      modified_probs = results['probabilities']\n",
        "\n",
        "      # Calculate comprehensiveness scores\n",
        "      comprehensiveness_scores = []\n",
        "      for idx, (prob, td) in enumerate(zip(test_results['probabilities'], test_data)):\n",
        "          label = int(td['hard_label'])\n",
        "          original_prob = prob[label] # Probability from normal prediction process for the label\n",
        "          modified_prob = modified_probs[idx][label]\n",
        "\n",
        "          # Comprehensiveness = original - modified (higher is better)\n",
        "          comp_score = original_prob - modified_prob\n",
        "          comprehensiveness_scores.append(comp_score)\n",
        "\n",
        "      return comprehensiveness_scores\n",
        "\n",
        "  def _compute_sufficiency(\n",
        "      self,\n",
        "      test_data: List[Dict],\n",
        "      test_results: List[Dict],\n",
        "      hard_predictions: List[np.ndarray]\n",
        "  ) -> List[float]:\n",
        "      \"\"\"\n",
        "      Compute sufficiency: how well do ONLY rationales predict?\n",
        "      Uses DataLoader approach for efficiency\n",
        "      \"\"\"\n",
        "      # Create modified dataset (keep only rationales in attention mask)\n",
        "      modified_data = []\n",
        "      for item, rationale_mask in zip(test_data, hard_predictions):\n",
        "          modified_item = self._create_sufficiency_instance(item, rationale_mask)\n",
        "          modified_data.append(modified_item)\n",
        "\n",
        "      # Create DataLoader\n",
        "      modified_dataset = self.dataset_class(modified_data)\n",
        "      modified_loader = DataLoader(\n",
        "          modified_dataset,\n",
        "          batch_size=self.batch_size,\n",
        "          shuffle=False\n",
        "      )\n",
        "\n",
        "      # Get predictions using model's predict method\n",
        "      results = self.model.predict(modified_loader, return_attentions=False)\n",
        "      modified_probs = results['probabilities']\n",
        "\n",
        "      # Calculate sufficiency scores\n",
        "      sufficiency_scores = []\n",
        "      for idx, (prob, td) in enumerate(zip(test_results['probabilities'], test_data)):\n",
        "          label = int(td['hard_label'])\n",
        "          original_prob = prob[label] # Probability from normal prediction process for the label\n",
        "          modified_prob = modified_probs[idx][label]\n",
        "\n",
        "          # Sufficiency = original - modified (lower/negative is better)\n",
        "          suff_score = original_prob - modified_prob\n",
        "          sufficiency_scores.append(suff_score)\n",
        "\n",
        "      return sufficiency_scores\n",
        "\n",
        "  def _create_comprehensiveness_instance(\n",
        "      self,\n",
        "      item: Dict,\n",
        "      rationale_mask: np.ndarray\n",
        "  ) -> Dict:\n",
        "      \"\"\"\n",
        "      Create instance for comprehensiveness: REMOVE rationales from attention\n",
        "      Keep: CLS + non-rationale content tokens + SEP\n",
        "      \"\"\"\n",
        "      input_ids = item['input_ids'].cpu().numpy().flatten()\n",
        "      orig_mask = item['attention_mask'].cpu().numpy().flatten()\n",
        "\n",
        "      # Start with original mask\n",
        "      new_mask = orig_mask.copy()\n",
        "\n",
        "      # Zero out rationale positions (except CLS and SEP)\n",
        "      for i in range(len(new_mask)):\n",
        "          if rationale_mask[i] == 1:  # This is a rationale\n",
        "              # Don't mask if it's CLS or SEP\n",
        "              if input_ids[i] not in self.special_token_ids:\n",
        "                  new_mask[i] = 0\n",
        "\n",
        "      return {\n",
        "          'input_ids': torch.tensor(input_ids).unsqueeze(0),\n",
        "          'attention_mask': torch.tensor(new_mask).unsqueeze(0),\n",
        "          'rationales': item['rationales'],\n",
        "          'hard_label': item['hard_label'],\n",
        "      }\n",
        "\n",
        "  def _create_sufficiency_instance(\n",
        "      self,\n",
        "      item: Dict,\n",
        "      rationale_mask: np.ndarray\n",
        "  ) -> Dict:\n",
        "      \"\"\"\n",
        "      Create instance for sufficiency: Keep ONLY rationales in attention\n",
        "      Keep: CLS + rationale tokens + SEP\n",
        "      \"\"\"\n",
        "      input_ids = item['input_ids'].cpu().numpy().flatten()\n",
        "      orig_mask = item['attention_mask'].cpu().numpy().flatten()\n",
        "\n",
        "      # Start with zeros\n",
        "      new_mask = np.zeros_like(orig_mask)\n",
        "\n",
        "      # Always keep CLS and SEP\n",
        "      for i in range(len(new_mask)):\n",
        "          if input_ids[i] in self.special_token_ids:\n",
        "              new_mask[i] = 1\n",
        "\n",
        "      # Keep rationale positions\n",
        "      for i in range(len(new_mask)):\n",
        "          if rationale_mask[i] == 1 and orig_mask[i] == 1:\n",
        "              new_mask[i] = 1\n",
        "\n",
        "      return {\n",
        "          'input_ids': torch.tensor(input_ids).unsqueeze(0),\n",
        "          'attention_mask': torch.tensor(new_mask).unsqueeze(0),\n",
        "          'rationales': item['rationales'],\n",
        "          'hard_label': item['hard_label'],\n",
        "      }"
      ],
      "metadata": {
        "id": "8toApSDiIVlT"
      },
      "id": "8toApSDiIVlT",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculator = FaithfulnessMetrics(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset_class=HateDataset,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "fj7X5QtPCPqX"
      },
      "id": "fj7X5QtPCPqX",
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_list = [item['input_ids'] for item in test_data]\n",
        "attention_masks_list = [item['attention_mask'] for item in test_data]\n",
        "human_rationales = [item['rationales'] for item in test_data]\n",
        "attention_scores = [item for item in result['attentions']]\n",
        "k = 5"
      ],
      "metadata": {
        "id": "E55iMG_4TTui"
      },
      "id": "E55iMG_4TTui",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_predictions = calculator._extract_top_k_tokens(\n",
        "  attention_scores,\n",
        "  attention_masks_list,\n",
        "  input_ids_list,\n",
        "  k\n",
        ")"
      ],
      "metadata": {
        "id": "MjQsDxN9MpLh"
      },
      "id": "MjQsDxN9MpLh",
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sufficiency_scores = calculator._compute_sufficiency(test_data, result, hard_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IFpJOpVcCT8",
        "outputId": "78590e24-ce42-484a-d9b3-2f24482e2abf"
      },
      "id": "5IFpJOpVcCT8",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference on 61 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:01<00:00, 30.83batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     0.5752\n",
            "  Test Accuracy: 0.7173\n",
            "  Test F1:       0.7145\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comprehensiveness_scores = calculator._compute_comprehensiveness(test_data, result, hard_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoQJFUeafsDZ",
        "outputId": "63d98a92-a7bd-454e-8814-d6b0f8f20b65"
      },
      "id": "hoQJFUeafsDZ",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference on 61 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:01<00:00, 31.74batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     0.8646\n",
            "  Test Accuracy: 0.5473\n",
            "  Test F1:       0.5328\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Comprehensiveness: {np.mean(comprehensiveness_scores)}\")\n",
        "print(f\"Sufficiency: {np.mean(sufficiency_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3_1MpGYfiWF",
        "outputId": "fac8bd4a-dad4-4e97-907e-ca3247e256e7"
      },
      "id": "r3_1MpGYfiWF",
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comprehensiveness: 0.19652852416038513\n",
            "Sufficiency: 0.054969824850559235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xai_results = calculator.compute_all_metrics(test_data, result, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOA14cGmYTea",
        "outputId": "3d9622c5-fb4f-43a7-dc62-c6952b86a63c"
      },
      "id": "IOA14cGmYTea",
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing ERASER metrics using DataLoader approach...\n",
            "\n",
            "[1/3] Computing plausibility metrics...\n",
            "[2/3] Computing comprehensiveness scores...\n",
            "Running inference on 61 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:01<00:00, 31.77batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     0.8646\n",
            "  Test Accuracy: 0.5473\n",
            "  Test F1:       0.5328\n",
            "============================================================\n",
            "[3/3] Computing sufficiency scores...\n",
            "Running inference on 61 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:01<00:00, 31.37batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     0.5752\n",
            "  Test Accuracy: 0.7173\n",
            "  Test F1:       0.7145\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xai_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZouzQIhIrZ",
        "outputId": "da760442-c186-4f74-e72d-663f8a04b8bc"
      },
      "id": "QdZouzQIhIrZ",
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auprc': np.float64(0.2183696732701997),\n",
              " 'token_f1': 0.3020481346114061,\n",
              " 'token_precision': 0.2280062467464862,\n",
              " 'token_recall': 0.44730392156862747,\n",
              " 'comprehensiveness': np.float32(0.19652852),\n",
              " 'sufficiency': np.float32(0.054969825),\n",
              " 'avg_rationale_length': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip all entries that are normal (label 0) in test data\n",
        "test_data_hate_only = []\n",
        "test_results_hate_only = {'attentions': [], 'probabilities': []}\n",
        "for idx, td in enumerate(test_data):\n",
        "  if td['hard_label'] == 1:\n",
        "    test_data_hate_only.append(td)\n",
        "    test_results_hate_only['attentions'].append(result['attentions'][idx])\n",
        "    test_results_hate_only['probabilities'].append(result['probabilities'][idx])"
      ],
      "metadata": {
        "id": "PS5yNQirhyXp"
      },
      "id": "PS5yNQirhyXp",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xai_results_hate_only = calculator.compute_all_metrics(test_data_hate_only, test_results_hate_only, k)"
      ],
      "metadata": {
        "id": "b7OuPPFyiwBU",
        "outputId": "b633a0cc-4cea-42bd-cb90-1b44534272ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b7OuPPFyiwBU",
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing ERASER metrics using DataLoader approach...\n",
            "\n",
            "[1/3] Computing plausibility metrics...\n",
            "[2/3] Computing comprehensiveness scores...\n",
            "Running inference on 36 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 36/36 [00:01<00:00, 29.67batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     1.1826\n",
            "  Test Accuracy: 0.3126\n",
            "  Test F1:       0.2382\n",
            "============================================================\n",
            "[3/3] Computing sufficiency scores...\n",
            "Running inference on 36 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 36/36 [00:01<00:00, 31.06batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test Results:\n",
            "  Test Loss:     0.5711\n",
            "  Test Accuracy: 0.6874\n",
            "  Test F1:       0.4074\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xai_results_hate_only"
      ],
      "metadata": {
        "id": "37a46XP9izqQ",
        "outputId": "53d7f1fa-7b5b-44b9-deb7-5476d88e8fcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "37a46XP9izqQ",
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auprc': np.float64(0.37660807521899525),\n",
              " 'token_f1': 0.41316856900292426,\n",
              " 'token_precision': 0.3838737949167397,\n",
              " 'token_recall': 0.44730392156862747,\n",
              " 'comprehensiveness': np.float32(0.3761324),\n",
              " 'sufficiency': np.float32(0.09439625),\n",
              " 'avg_rationale_length': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ebb232a0b9649789495ec0c8a519e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d755aa71d5a1461cb932778dc5deaf52",
              "IPY_MODEL_30b2fc6ceebb4da083da94a206cdc32e",
              "IPY_MODEL_f872f5f79a884eaca0f07e00bc1a2eca"
            ],
            "layout": "IPY_MODEL_1ac419c560cb44149a6b54d2c256e1aa"
          }
        },
        "d755aa71d5a1461cb932778dc5deaf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40ac1cd6e2344ca8d8ede79e35791cb",
            "placeholder": "​",
            "style": "IPY_MODEL_000d556ee6514ee4a84badad7cce732d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "30b2fc6ceebb4da083da94a206cdc32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222943fb54e5426d89b2d50051135306",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6168a397e2994c0289bf267be8bff0e7",
            "value": 48
          }
        },
        "f872f5f79a884eaca0f07e00bc1a2eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5921c0c4994155a08f060c98de0228",
            "placeholder": "​",
            "style": "IPY_MODEL_0466e0260a5f4774af5c4b76b495d15f",
            "value": " 48.0/48.0 [00:00&lt;00:00, 873B/s]"
          }
        },
        "1ac419c560cb44149a6b54d2c256e1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40ac1cd6e2344ca8d8ede79e35791cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000d556ee6514ee4a84badad7cce732d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "222943fb54e5426d89b2d50051135306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6168a397e2994c0289bf267be8bff0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed5921c0c4994155a08f060c98de0228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0466e0260a5f4774af5c4b76b495d15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "838074dd3de54ba28ff6888918598f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4108f81df6394bb1956157ffa08d5b19",
              "IPY_MODEL_6dcba1504ae6444a9f8b1eb310b1c0ba",
              "IPY_MODEL_2149e2e0f02d44be95617cf8c57dc8e8"
            ],
            "layout": "IPY_MODEL_955bc92f2d6141949e91648f36940ed9"
          }
        },
        "4108f81df6394bb1956157ffa08d5b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01f0ad4c4f884d5ab4bae38a6d5b8f12",
            "placeholder": "​",
            "style": "IPY_MODEL_658618d078554305b8d86b1a882f9ae9",
            "value": "config.json: 100%"
          }
        },
        "6dcba1504ae6444a9f8b1eb310b1c0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ac744ceb77418baeea1a40b2213bcf",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_036b2b14b78a46beb319571bc408bf94",
            "value": 483
          }
        },
        "2149e2e0f02d44be95617cf8c57dc8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42983923305347428db2a3acb7d8fa98",
            "placeholder": "​",
            "style": "IPY_MODEL_95a276c276594117b51a9ed4361ad4d3",
            "value": " 483/483 [00:00&lt;00:00, 16.1kB/s]"
          }
        },
        "955bc92f2d6141949e91648f36940ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f0ad4c4f884d5ab4bae38a6d5b8f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658618d078554305b8d86b1a882f9ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ac744ceb77418baeea1a40b2213bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036b2b14b78a46beb319571bc408bf94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42983923305347428db2a3acb7d8fa98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95a276c276594117b51a9ed4361ad4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d514fc32c3b14890866e4e340eb65ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27983a49e3af4cc799d4b47291fa1d2e",
              "IPY_MODEL_a8e708b18cdb40078565f90ca9aec543",
              "IPY_MODEL_2ec85da142384b2499d0d5cec5516cb6"
            ],
            "layout": "IPY_MODEL_c6a377b8f1994f7ea5853c5ea47c072c"
          }
        },
        "27983a49e3af4cc799d4b47291fa1d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cbf881bf084483594c4982f61ddee22",
            "placeholder": "​",
            "style": "IPY_MODEL_555f094a99a448ed92206c2b2e40a48e",
            "value": "vocab.txt: 100%"
          }
        },
        "a8e708b18cdb40078565f90ca9aec543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09f9d26e7554480be056472a37727b9",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85183a453759410090f84533fd6a94d4",
            "value": 231508
          }
        },
        "2ec85da142384b2499d0d5cec5516cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658de63d6be44d67abae51be45398ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_5a27b15a14d0485d9bec469f9fbc8297",
            "value": " 232k/232k [00:00&lt;00:00, 5.98MB/s]"
          }
        },
        "c6a377b8f1994f7ea5853c5ea47c072c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbf881bf084483594c4982f61ddee22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555f094a99a448ed92206c2b2e40a48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e09f9d26e7554480be056472a37727b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85183a453759410090f84533fd6a94d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "658de63d6be44d67abae51be45398ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a27b15a14d0485d9bec469f9fbc8297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0bf17679f9b4e74be363704aa7bf120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_624199c0f53447e7b4e32d371e4016eb",
              "IPY_MODEL_84892e9a9e0f4dc8b74b975392618dc6",
              "IPY_MODEL_662feb5d7e6946a18fba9a23145fc034"
            ],
            "layout": "IPY_MODEL_1be37b84a1ae427fa1a636cdd98a6fd7"
          }
        },
        "624199c0f53447e7b4e32d371e4016eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199507e489064a3fb942faf130588a3d",
            "placeholder": "​",
            "style": "IPY_MODEL_9cae2ba8f08e46108daebf7cf8de1618",
            "value": "tokenizer.json: 100%"
          }
        },
        "84892e9a9e0f4dc8b74b975392618dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a64806bec5463c80471893e695e179",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df22cfc7b3de4d5595f10e4250223801",
            "value": 466062
          }
        },
        "662feb5d7e6946a18fba9a23145fc034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1b35c05596461d8b8005b6a62506da",
            "placeholder": "​",
            "style": "IPY_MODEL_e31b9ffcc76a4885a4b32e84a2fab004",
            "value": " 466k/466k [00:00&lt;00:00, 3.76MB/s]"
          }
        },
        "1be37b84a1ae427fa1a636cdd98a6fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199507e489064a3fb942faf130588a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cae2ba8f08e46108daebf7cf8de1618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4a64806bec5463c80471893e695e179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df22cfc7b3de4d5595f10e4250223801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e1b35c05596461d8b8005b6a62506da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31b9ffcc76a4885a4b32e84a2fab004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a035f097a51b4e59b5f240e08a959dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3049e83d2f184ca2b7657db368f49a1d",
              "IPY_MODEL_ee1a88ab031c4327ad18b3a48929bab0",
              "IPY_MODEL_6ea187bc06d84f018673dfc981571a6e"
            ],
            "layout": "IPY_MODEL_7c2b46d111114553b94fcd2351e9f7bd"
          }
        },
        "3049e83d2f184ca2b7657db368f49a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f9d7443369a4cbf97048d9952396b58",
            "placeholder": "​",
            "style": "IPY_MODEL_2642b7f8abf24bfabef78ef219768375",
            "value": "model.safetensors: 100%"
          }
        },
        "ee1a88ab031c4327ad18b3a48929bab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ab7c8eca5442a88af511856f58b271",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_effb7cca8a914550a68775728bdeb881",
            "value": 267954768
          }
        },
        "6ea187bc06d84f018673dfc981571a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_606c6a11e2564fc68ec19f701e48c625",
            "placeholder": "​",
            "style": "IPY_MODEL_c46fe7448c5a46428cd007265094139f",
            "value": " 268M/268M [00:03&lt;00:00, 64.7MB/s]"
          }
        },
        "7c2b46d111114553b94fcd2351e9f7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9d7443369a4cbf97048d9952396b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2642b7f8abf24bfabef78ef219768375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ab7c8eca5442a88af511856f58b271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effb7cca8a914550a68775728bdeb881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "606c6a11e2564fc68ec19f701e48c625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46fe7448c5a46428cd007265094139f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}